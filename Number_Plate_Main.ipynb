{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PVlANLJ4tBe"
      },
      "outputs": [],
      "source": [
        "# pip install tensorflow==2.13.0\n",
        "# pip install easyocr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T88BkiBlDKkc"
      },
      "source": [
        "<u>Gdrive</u>,\n",
        "<br>whole_files_9000st.zip: //drive.google.com/file/d/1729iEumzufmOj3TIMj4yCvOtNR9AR9cG/view?usp=sharing\n",
        "<br>only_workspace_9000st.zip: //drive.google.com/file/d/1GIe1Y9foZdvoPbLWhVvQ5sQ9y2obIEhP/view?usp=sharing\n",
        "<br>my_model_9000st.zip: //drive.google.com/file/d/1i93ZIJPiQiUQ4984JUqnfUlc7dGz4kQv/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M1-J0Gf3qV9"
      },
      "outputs": [],
      "source": [
        "# #  TF workspace zip with models\n",
        "# gdown 1729iEumzufmOj3TIMj4yCvOtNR9AR9cG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wluwau1S3qKf"
      },
      "outputs": [],
      "source": [
        "# # model is in .zip format. so unzip it\n",
        "# import os\n",
        "# import zipfile\n",
        "# zip_ref = zipfile.ZipFile('/content/Whole_files_9000st.zip', 'r') # source\n",
        "# zip_ref.extractall('/content') # Destination\n",
        "# zip_ref.close()\n",
        "# os.remove('/content/Whole_files_9000st.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phwn7G6qVE5Z"
      },
      "outputs": [],
      "source": [
        "# # delete unwanted files. need to make it before uploading zip\n",
        "# os.remove('/content/detection_results.csv')\n",
        "# os.remove('/content/Car_License_plate_detection_by_larxel.zip')\n",
        "# import shutil\n",
        "# shutil.rmtree('/content/Detection_Images')\n",
        "# shutil.rmtree('/content/dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-hbeWbvhwwY"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2AqcAD3a9je"
      },
      "source": [
        "# **Folder structures**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hYm3wMBYvck"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
        "\n",
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME),\n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'),\n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'),\n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        " }\n",
        "\n",
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baVgvRrR4Lkh"
      },
      "outputs": [],
      "source": [
        "# if os.name=='nt':\n",
        "#     !pip install wget\n",
        "#     import wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXvLW8NmbpPi"
      },
      "outputs": [],
      "source": [
        "# # Install Tensorflow Object Detection\n",
        "# if os.name=='posix':\n",
        "#      apt-get install protobuf-compiler\n",
        "#     cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install .\n",
        "#     pip install tensorflow==2.13.0\n",
        "\n",
        "# if os.name=='nt':\n",
        "#     url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "#     wget.download(url)\n",
        "#     move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "#     cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "#     os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))\n",
        "#     cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "#     cd Tensorflow/models/research/slim && pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPhSNfGZdVvn"
      },
      "outputs": [],
      "source": [
        "# VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# # Verify Installation\n",
        "# python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA1nui3TJ5AN"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBO2NviSqCNZ"
      },
      "source": [
        "# Load Train Model From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrWLdC4nr0Tx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPpnhdX4p7tP"
      },
      "outputs": [],
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-9')).expect_partial()  # change checkpoint\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg0bD7a8qUIm"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIWtLr7lqYPx"
      },
      "source": [
        "# Detect from an Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhqxlOM5sQNB"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJgeuu6YsQIn"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyjw5iOMqWs0"
      },
      "outputs": [],
      "source": [
        "def find_plate(img_path, min_score_thresh=.6):\n",
        "    # IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'Cars420.png') # Replace file name\n",
        "    # IMAGE_PATH = img_path\n",
        "\n",
        "    # img = cv2.imread(IMAGE_PATH)\n",
        "      # img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # added\n",
        "    image_np = np.array(img_path)     #img\n",
        "\n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_detections,\n",
        "        detections['detection_boxes'],\n",
        "        detections['detection_classes']+label_id_offset,\n",
        "        detections['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=5,\n",
        "        min_score_thresh=min_score_thresh, # min 0.8\n",
        "        agnostic_mode=False\n",
        "    )\n",
        "\n",
        "    plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "    return image_np_with_detections, detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PqRqFQggMvB"
      },
      "outputs": [],
      "source": [
        "image_np_with_detections, detections = find_plate(os.path.join(paths['IMAGE_PATH'], 'test', 'Cars423.png'), 0.3 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLoHg81VbWcq"
      },
      "source": [
        "# Apply OCR to Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQUiTCNtfu6h"
      },
      "outputs": [],
      "source": [
        "import easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNETOuksjLF4"
      },
      "outputs": [],
      "source": [
        "detection_threshold = 0.7\n",
        "region_threshold = 0.5 # change to o.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-P2dJ7TpiXi"
      },
      "outputs": [],
      "source": [
        "def filter_text(region, ocr_result, region_threshold=0.6):\n",
        "    rectangle_size = region.shape[0]*region.shape[1]\n",
        "\n",
        "    plate = []\n",
        "    for result in ocr_result:\n",
        "        length = np.sum(np.subtract(result[0][1], result[0][0]))\n",
        "        height = np.sum(np.subtract(result[0][2], result[0][1]))\n",
        "\n",
        "        if length*height / rectangle_size > region_threshold:\n",
        "            plate.append(result[1])\n",
        "    return plate\n",
        "\n",
        "def ocr_it(image, detections, detection_threshold=0.7, region_threshold=0.6):\n",
        "\n",
        "    # Scores, boxes and classes above threhold\n",
        "    scores = list(filter(lambda x: x> detection_threshold, detections['detection_scores']))\n",
        "    boxes = detections['detection_boxes'][:len(scores)]\n",
        "    classes = detections['detection_classes'][:len(scores)]\n",
        "\n",
        "    # Full image dimensions\n",
        "    width = image.shape[1]\n",
        "    height = image.shape[0]\n",
        "\n",
        "    # Apply ROI filtering and OCR\n",
        "    for idx, box in enumerate(boxes):\n",
        "        roi = box*[height, width, height, width]\n",
        "        region = image[int(roi[0]):int(roi[2]),int(roi[1]):int(roi[3])]\n",
        "        reader = easyocr.Reader(['en'])\n",
        "        ocr_result = reader.readtext(region)\n",
        "\n",
        "        text = filter_text(region, ocr_result, region_threshold)\n",
        "\n",
        "        plt.imshow(cv2.cvtColor(region, cv2.COLOR_BGR2RGB))\n",
        "        plt.show()\n",
        "        print(text)\n",
        "        return text, region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyPSBRRapiUq"
      },
      "outputs": [],
      "source": [
        "text, region = ocr_it(image_np_with_detections, detections, detection_threshold, region_threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR6D9hRppsVy"
      },
      "source": [
        "# Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZaUBsjFpvnX"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKl0DnyOyJWR"
      },
      "outputs": [],
      "source": [
        "os.mkdir(os.path.join('/content', 'Detection_Images'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sc5krxLpu-C"
      },
      "outputs": [],
      "source": [
        "def save_results(text, region, csv_filename, folder_path):\n",
        "    img_name = '{}.jpg'.format(uuid.uuid1())\n",
        "\n",
        "    cv2.imwrite(os.path.join(folder_path, img_name), region)\n",
        "\n",
        "    with open(csv_filename, mode='a', newline='') as f:\n",
        "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "        csv_writer.writerow([img_name, text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9zP0YKyp1zs"
      },
      "outputs": [],
      "source": [
        "region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77dfybS_p1pe"
      },
      "outputs": [],
      "source": [
        "save_results(text, region, 'detection_results.csv', 'Detection_Images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoJ5sEUrp5N9"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYy_SpkPp5zg"
      },
      "source": [
        "# From Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjEzJbykpO-P"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import IPython.display as ipd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS12ozaXLtdV"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFmz_nuPkMk8"
      },
      "outputs": [],
      "source": [
        "video_path = '/content/traffic_15s_oneway.mp4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB2hyCk0lNcS"
      },
      "outputs": [],
      "source": [
        "ipd.Video(video_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "furF6r2Rmcj7"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"\n",
        "    <video alt=\"test\" controls>\n",
        "        <source src=\"video_path\" type=\"video/mp4\">\n",
        "    </video>\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBZYsjszl3Bp"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(video_path)\n",
        "print(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print(cap.get(cv2.CAP_PROP_FPS))\n",
        "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iubpfV84mJK_"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "# os.mkdir('out')\n",
        "while(cap.isOpened()):\n",
        "  ret, frame = cap.read()\n",
        "  if ret:\n",
        "    cv2.imwrite(f'out/{i}.png', frame)\n",
        "  print(i)\n",
        "  i +=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxxWhPve0sD7"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(video_path)\n",
        "# ret, frame = cap.read()\n",
        "\n",
        "# # img = cv2.imread(frame)\n",
        "# # img.shape\n",
        "# # type(img)\n",
        "# # type(frame)\n",
        "# a, v = find_plate(frame, 0.1)\n",
        "\n",
        "ret, frame2 = cap.read()\n",
        "# a,c = find_plate(frame2, 0.1)\n",
        "\n",
        "# for i in range(5):\n",
        "while cap.isOpened():\n",
        "  ret, frame = cap.read()\n",
        "  if not ret:\n",
        "    break\n",
        "  if cap.get(cv2.CAP_PROP_POS_FRAMES) % 100 == 0:\n",
        "    a, b = find_plate(frame, 0.01)\n",
        "    # print('frme')\n",
        "    m = ocr_it(a, b)\n",
        "    # print(f' , {c} .')\n",
        "    # cv2.imshow(m)\n",
        "\n",
        "# cap.get(cv2.CAP_PROP_POS_FRAMES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbEXJ1wPmJI2"
      },
      "outputs": [],
      "source": [
        "# ret, frame = cap.read()\n",
        "# find_plate(os.path.join('content', 'out', 'o.png'))\n",
        "\n",
        "original_img = plt.imread('/content/Tensorflow/workspace/images/test/Cars415.png')\n",
        "vid_img = plt.imread('/content/out/100.png')\n",
        "\n",
        "\n",
        "# plt.imshow(original_img)\n",
        "# plt.imshow(vid_img)\n",
        "\n",
        "print('original', original_img.shape)\n",
        "print(vid_img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImtEtuzCmJF1"
      },
      "outputs": [],
      "source": [
        "a, b = find_plate('/content/Tensorflow/workspace/images/test/Cars416.png')\n",
        "print('n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkPu1Mv2mJCr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9z-7gVBAxzTZ"
      },
      "outputs": [],
      "source": [
        "a, b = find_plate('/content/out/405.png', 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eg8jJmMEmI_i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsldRBYOkI08"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fayS4yEvbyh"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('/content/4513830-sd_640_360_30fps.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykD9zXolvs_l"
      },
      "outputs": [],
      "source": [
        "# แปลงไฟล์เป็น string ในรูปแบบ data url\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('/content/｜ Indian beautiful Vehicles are running on road  ｜ Indian cars ｜ Indian trucks ｜ Indian road ｜ [UgkxcGO07DNJoN1ruVaBDIxXwh0ROpPHo7O7].mkv','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBaniUDNvtyW"
      },
      "outputs": [],
      "source": [
        "# แสดงผลด้วย vdo tag    ใครงง ก็ไปเรียน HTML ใน Sololearn ได้\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfJqcqoMxSDL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def preprocess_frame(frame):\n",
        "    # Your preprocessing steps here\n",
        "    # For example, you can convert the frame to grayscale\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    # Or apply a Gaussian blur\n",
        "    blurred_frame = cv2.GaussianBlur(gray_frame, (5, 5), 0)\n",
        "    return blurred_frame\n",
        "\n",
        "def process_video(input_video_path, output_video_path):\n",
        "    # Open the input video file\n",
        "    input_video = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "    # Get the frame rate of the input video\n",
        "    frame_rate = int(input_video.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    # Create a VideoWriter object to save the output video\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    output_video = cv2.VideoWriter(output_video_path, fourcc, frame_rate, (int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
        "\n",
        "    # Read each frame from the input video\n",
        "    while input_video.isOpened():\n",
        "        ret, frame = input_video.read()\n",
        "\n",
        "        # Check if the frame was read correctly\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Preprocess the frame\n",
        "        processed_frame = preprocess_frame(frame)\n",
        "\n",
        "        # Write the processed frame to the output video\n",
        "        output_video.write(processed_frame)\n",
        "\n",
        "    # Release the input and output video files\n",
        "    input_video.release()\n",
        "    output_video.release()\n",
        "\n",
        "# Example usage\n",
        "input_video_path = 'input_video.mp4'\n",
        "output_video_path = 'output_video.mp4'\n",
        "process_video(input_video_path, output_video_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
